# Prefix Search Implementation

This document describes the implementation of the prefix search system for the cargo catalog assignment.

## Quick Start

### Prerequisites

- Docker and Docker Compose
- Python 3.11+ (for local development)

### Setup and Run

**Option 1: Define venv and use setup script (recommended)**
```bash
python3.12 -m venv .venv
source .venv/bin/activate
pip install -r requrements.txt
./setup.sh
```

**Option 2: Manual setup**
```bash
# 1. Start Elasticsearch and search service
docker compose up 

# 2. Wait for Elasticsearch to be ready (about 30 seconds)
# Check health: curl http://localhost:9200/_cluster/health

# 3. Load catalog into Elasticsearch (embeddings generated by default)
python tools/load_catalog.py --host localhost --port 9200

# 4. Test the search service
curl "http://localhost:5000/search?q=масло"

# 5. Run evaluation
python tools/evaluate.py --type open
```

### Docker Compose Services

- **elasticsearch**: Runs on port 9200
- **search-service**: Flask API on port 5000

## Features

### Hybrid Search (Text + Embeddings)

The system supports hybrid search combining:
- **Text-based search**: Prefix matching, keyboard layout switching, transliteration
- **Vector search**: Semantic similarity using embeddings

### Embeddings

- **Default**: Embeddings are generated by default when loading the catalog
- **Model**: Uses `paraphrase-multilingual-MiniLM-L12-v2` (384 dimensions)
- **Storage**: Embeddings stored in Elasticsearch `dense_vector` field
- **Auto-detection**: Search service automatically detects if embeddings are available in the index
- **Search**: Hybrid search combines text and vector results with normalized score fusion


## Index Schema and Analyzers

### Index Structure

The `catalog` index contains the following fields:

- `id` (keyword) - Product ID
- `name` (text) - Product name with prefix analyzer
- `category` (keyword + text) - Category with both exact and text search
- `brand` (text + keyword) - Brand name
- `weight` (float) - Weight/volume value
- `weight_unit` (keyword) - Unit (kg, g, l, ml, etc.)
- `package_size` (integer) - Package size
- `keywords` (text) - Searchable keywords
- `description` (text) - Product description
- `price` (float) - Price
- `image_url` (keyword) - Image URL
- `embedding` (dense_vector) - Semantic embedding vector (384 dimensions)

### Custom Analyzers

#### prefix_analyzer
- **Tokenizer**: standard
- **Filters**: lowercase, russian_stop, prefix_edge_ngram
- **Purpose**: Index-time analyzer for prefix matching (2-15 characters)
- **Note**: Keyboard layout switching is handled in the search service code, not in the analyzer

#### search_analyzer
- **Tokenizer**: standard
- **Filters**: lowercase, russian_stop
- **Purpose**: Query-time analyzer for search

#### prefix_edge_ngram Filter
- **Type**: edge_ngram
- **Min gram**: 2
- **Max gram**: 15
- **Token chars**: letter, digit


## Search Logic

### Query Normalization

1. **Numeric Attribute Extraction**: Extracts weight/volume from query (e.g., "10л", "5kg")
2. **Keyboard Layout Switching**: Detects and switches between qwerty and йцукен layouts
3. **Transliteration**: Converts Cyrillic to Latin (using `transliterate` library)
4. **Query Variations**: Generates multiple query variations for better recall

### Ranking Strategy

The search uses hybrid ranking combining text and vector search:

**Text-based boosts:**
- **Name exact match**: boost 5.0
- **Name prefix match**: boost 4.0 (using `match_bool_prefix`)
- **Brand match**: boost 3.0
- **Keywords match**: boost 2.0
- **Category match**: boost 1.5
- **Description match**: boost 1.0
- **Numeric attribute match**: boost 2.0 (if weight/volume matches within ±20% tolerance)

**Vector search:**
- **Semantic similarity**: Uses cosine similarity on embeddings
- **Separate execution**: Text and vector searches run independently
- **Score fusion**: Results merged with normalized scores
  - Text weight: 0.7 (70%)
  - Vector weight: 0.3 (30%)
- **Candidates**: Searches 5x top_k candidates for better recall
- **Buffer**: Fetches 2x top_k results to account for filtering and merging

### Noise Filtering

Results are filtered to remove noise after hybrid score fusion:

1. **Text matching**: At least one query word must appear in name, brand, or category
2. **Score threshold**: Results with hybrid score ≥ 0.5 are kept (bypasses text matching requirement)
3. **Purpose**: Removes semantically related but textually irrelevant results from vector search

## Supported Scenarios

### 1. Short Prefixes (2+ letters)
- Example: "ма" → finds "масло", "макароны"
- Uses edge_ngram analyzer with min_gram=2

### 2. Keyboard Layout Switching
- Example: "xfq" → finds "чай" (qwerty layout mistake)
- Handled in search service's query normalization (not in Elasticsearch analyzer)

### 3. Transliteration
- Example: "prosecco" → finds products with "prosecco" in name/brand
- Uses transliterate library for Cyrillic → Latin

### 4. Numeric Attributes
- Example: "масло раст 10л" → finds sunflower oil with ~10L volume
- Extracts numeric patterns and boosts matching products

### 5. Mixed Languages
- Example: "adapter usb c" → finds USB-C adapters
- Handles both Cyrillic and Latin text

### 6. Typos and Abbreviations
- Example: "греч не" → finds "гречневая"
- Uses prefix matching and fuzzy logic

## Evaluation Metrics

The evaluation script calculates comprehensive metrics:

- **Precision@1**: Fraction of top-1 results that are relevant
- **Precision@K**: Fraction of top-K results that are relevant (configurable, default K=3)
- **Precision@top_k**: Fraction of all returned results that are relevant
- **Coverage (any)**: Fraction of queries that return at least one result
- **Coverage (relevant)**: Fraction of queries that return at least one relevant result
- **Relevant in top_k**: Count of relevant results in top K
- **Latency**: Average response time in milliseconds

**Relevance Heuristic:**
- Requires 60% of query tokens to match as prefixes in result fields (name, brand, category, keywords)
- Minimum score threshold (default: 0.5) must be met
- Adapts to query length (longer queries require more matches)

### Running Evaluation

```bash
# Evaluate open queries (default)
python tools/evaluate.py --type open

# Evaluate hidden queries
python tools/evaluate.py --type hidden

# Evaluate all queries (generates separate files for open and hidden)
python tools/evaluate.py --type all

# Customize evaluation parameters
python tools/evaluate.py --top-k 10 --precision-k 5 --relevance-threshold 0.3

# Evaluate with embeddings enabled
python tools/evaluate.py --use-embeddings --type all
```

**Output:**
- Console: Per-query metrics and summary statistics
- CSV: Detailed results with top 3 results, scores, precision metrics, coverage, and judgment labels

## API Endpoints

### GET /health
Health check endpoint.

**Response:**
```json
{"status": "ok"}
```

### GET /search?q=<query>&top_k=<number>&use_embeddings=<bool>
Search endpoint.

**Parameters:**
- `q` (required): Search query (supports Cyrillic and Latin characters)
- `top_k` (optional): Number of results (default: 5)
- `use_embeddings` (optional): Override embedding usage (default: uses service setting)

**Response:**
```json
{
  "query": "масло",
  "count": 5,
  "results": [
    {
      "id": "P0544",
      "name": "Масло сливочное премиум «Teos» 200г",
      "category": "Молочные продукты",
      "brand": "Teos",
      "weight": 200.0,
      "weight_unit": "g",
      "price": 685.52,
      "image_url": "https://example.com/p/P0544.jpg",
      "score": 0.95
    }
  ]
}
```

**Note:** The service automatically detects if embeddings are available in the index. If embeddings are not present, vector search is automatically disabled.


## Implementation Details

### Query Processing Flow

1. **Input**: User query (e.g., "масло раст 10л")
2. **Normalization**:
   - Extract numeric: `{"volume_l": 10}`
   - Remove numeric from text: "масло раст"
   - Generate variations: ["масло раст", "vfkj hfcn"] (layout switch)
   - Generate query embedding if embeddings are available
3. **Text Search**:
   - Multi-match across name, brand, keywords, category, description
   - Boost numeric matches if present (within ±20% tolerance)
   - Fetch 2x top_k results for buffer
4. **Vector Search** (if embeddings available):
   - Execute separate knn query with query embedding
   - Fetch 2x top_k results for buffer
5. **Score Fusion**:
   - Merge text and vector results by document ID
   - Normalize scores (divide by max score in each list)
   - Combine: `combined_score = 0.7 * norm_text + 0.3 * norm_vector`
6. **Post-processing**:
   - Filter noise results (text match or score ≥ 0.5)
   - Sort by combined score
   - Return top K results

### Keyboard Layout Mapping

The layout mapping covers:
- Letters: q→й, w→ц, e→у, etc.
- Punctuation: [→х, ]→ъ, ;→ж, etc.
- Bidirectional: Both qwerty→йцукен and йцукен→qwerty

### Numeric Attribute Parsing

Supports patterns:
- `10л`, `10l`, `10лт` → volume in liters
- `5кг`, `5kg` → weight in kilograms
- `500г`, `500g` → weight in grams
- `1000мл`, `1000ml` → volume in milliliters

**Matching tolerance**: ±20% (0.8x to 1.2x of target value) to account for product variations and unit conversions

## Known Limitations and Future Improvements

### Current Limitations

1. **Transliteration**: Only handles Cyrillic→Latin, not reverse
2. **Numeric Matching**: Weight/volume matching is approximate (±20% tolerance)
3. **Noise Filtering**: Heuristic-based, may filter some valid results
4. **Evaluation**: Uses heuristic relevance (no ground truth labels)
5. **No Learning**: No machine learning for ranking improvements

## Reflection

### Challenges Encountered

1. **Edge N-gram Configuration**: Initially tried to use edge_ngram as tokenizer, but it should be a filter
2. **Numeric Attribute Matching**: Decided to use boosts instead of strict filters to maintain recall
3. **Noise Filtering**: Balancing precision and recall - too strict filters remove valid results
4. **Hybrid Search Implementation**: Elasticsearch 8.x knn queries don't support boost parameter; implemented separate searches with score fusion
5. **Russian Encoding**: Fixed UTF-8 encoding issues in Flask responses and query parameter handling
6. **Embedding Detection**: Added automatic detection of embedding field availability to gracefully handle indices without embeddings

### Design Decisions

1. **Elasticsearch over Faiss/Milvus**: Chosen for better text search capabilities and analyzers
2. **Multi-match with Boosts**: Provides flexibility while maintaining relevance
3. **Hybrid Search with Score Fusion**: Separate text and vector searches merged with normalized scores (70/30 split)
4. **Post-processing Filtering**: Allows fine-grained control over result quality
5. **Embeddings by Default**: Generate embeddings during catalog loading to enable semantic search out of the box
6. **Auto-detection**: Service automatically detects embedding availability to gracefully degrade to text-only search
7. **Docker Compose**: Simplifies deployment and ensures consistency

### Test Scenarios Covered

The solution handles the key scenarios from `prefix_queries.csv`:

- ✅ Short prefixes ("ма", "pr")
- ✅ Keyboard layout mistakes ("xfq" → "чай")
- ✅ Transliteration ("prosecco", "riesling")
- ✅ Numeric attributes ("10л", "5kg")
- ✅ Mixed languages ("adapter usb c")
- ✅ Abbreviations ("греч не" → "гречневая")
- ✅ Multi-word queries ("масло раст 10л")

### Performance

- **Indexing**: ~1000 products in < 5 seconds
- **Search Latency**: < 100ms for most queries
- **Coverage**: Target ≥70% (to be validated with evaluation)


## Loading Catalog

```bash
# Load catalog with embeddings (default)
python tools/load_catalog.py

# Load catalog without embeddings
python tools/load_catalog.py --no-embeddings

# Custom embedding model
python tools/load_catalog.py --embedding-model "sentence-transformers/all-MiniLM-L6-v2"

# Custom Elasticsearch host/port
python tools/load_catalog.py --host localhost --port 9200
```

**Note:** Embeddings are generated by default. The search service will automatically detect if embeddings are available in the index and enable/disable vector search accordingly.


